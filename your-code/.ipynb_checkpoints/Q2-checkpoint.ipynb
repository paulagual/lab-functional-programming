{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to enhance the `get_bow_from_docs` function so that it will work with HTML webpages. In HTML, there are a lot of messy codes such as HTML tags, Javascripts, [unicodes](https://www.w3schools.com/charsets/ref_utf_misc_symbols.asp) that will mess up your bag of words. We need to clean up those junk before generating BoW.\n",
    "\n",
    "Next, what you will do is to define several new functions each of which is specialized to clean up the HTML codes in one aspect. For instance, you can have a `strip_html_tags` function to remove all HTML tags, a `remove_punctuation` function to remove all punctuation, a `to_lower_case` function to convert string to lowercase, and a `remove_unicode` function to remove all unicodes.\n",
    "\n",
    "Then in your `get_bow_from_doc` function, you will call each of those functions you created to clean up the HTML before you generate the corpus.\n",
    "\n",
    "Note: Please use Python string operations and regular expression only in this lab. Do not use extra libraries such as `beautifulsoup` because otherwise you loose the purpose of practicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your string handling functions below\n",
    "# Minimal 3 functions\n",
    "\n",
    "#function to remove all HTML tags\n",
    "def strip_html_tags(html):\n",
    "    pattern=\"<.+>\"\n",
    "    clean_html = re.sub(pattern,'',html)\n",
    "    return clean_html\n",
    "\n",
    "\n",
    "# function to remove all punctuation\n",
    "def remove_punctuation(html):\n",
    "    pattern=\"[^a-zA-Z0-9 ]|\\n\"\n",
    "    clean_html = re.sub(pattern,'',html)\n",
    "    return clean_html\n",
    "\n",
    "#function to convert string to lowercase\n",
    "def to_lower_case(html):\n",
    "    clean_html = html.lower()\n",
    "    return clean_html\n",
    "\n",
    "#function to remove all unicodes\n",
    "def remove_unicode(html):\n",
    "    pattern = \"[^\\x00-\\x7F]+|&\\w+?;\"\n",
    "    clean_html = re.sub(pattern,' ',html)\n",
    "    return clean_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, paste your previously written `get_bow_from_docs` function below. Call your functions above at the appropriate place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_from_docs(docs, stop_words=[]):\n",
    "    # In the function, first define the variables you will use such as `corpus`, `bag_of_words`, and `term_freq`.\n",
    "    corpus = []\n",
    "    bag_of_words = []\n",
    "    term_freq = []\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `docs` and read the content of each doc into a string in `corpus`.\n",
    "    Remember to convert the doc content to lowercases and remove punctuation.\n",
    "    \"\"\"\n",
    "    for file in docs:\n",
    "        file_txt = open(file, \"r\")  \n",
    "        txt = file_txt.read()\n",
    "        txt = strip_html_tags(txt)\n",
    "        txt = to_lower_case(txt)\n",
    "        txt = remove_unicode(txt)\n",
    "        txt = remove_punctuation(txt)\n",
    "        pattern = \"\\w+\"\n",
    "        txt = (\" \".join(re.findall(pattern, txt)))\n",
    "        corpus.append(txt)\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `corpus`. Append the terms in each doc into the `bag_of_words` array. The terms in `bag_of_words` \n",
    "    should be unique which means before adding each term you need to check if it's already added to the array.\n",
    "    In addition, check if each term is in the `stop_words` array. Only append the term to `bag_of_words`\n",
    "    if it is not a stop word.\n",
    "    \"\"\"\n",
    "    for string in corpus:\n",
    "        terms = string.split()\n",
    "        for term in terms:\n",
    "            if term not in bag_of_words and term not in stop_words:\n",
    "                bag_of_words.append(term)\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `corpus` again. For each doc string, count the number of occurrences of each term in `bag_of_words`. \n",
    "    Create an array for each doc's term frequency and append it to `term_freq`.\n",
    "    \"\"\"\n",
    "    for string in corpus:\n",
    "        string_terms = string.split()\n",
    "        string_term_count = []\n",
    "        for term in bag_of_words:\n",
    "            count = 0\n",
    "            for i in range(0, len(string_terms)):\n",
    "                if term == string_terms[i]:\n",
    "                    count += 1\n",
    "            string_term_count.append(count)   \n",
    "        term_freq.append(string_term_count)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"bag_of_words\": bag_of_words,\n",
    "        \"term_freq\": term_freq\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, read the content from the three HTML webpages in the `your-codes` directory to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bag_of_words': ['javascriptincludetag', 'ossmaxcdncomlibshtml5shiv370html5shivjs', 'ossmaxcdncomlibsrespondjs142respondminjsthis', 'course', 'enables', 'students', 'fledged', 'data', 'analyst', '9', 'weeks', 'develop', 'practical', 'skills', 'useful', 'industry', 'rampup', 'prework', 'learn', 'intermediate', 'topics', 'analytics', 'using', 'pandas', 'engineering', 'create', 'application', 'real', 'datasets', 'you39ll', 'use', 'python', 'business', 'intelligencethrough', 'bootcamp', 'doing', 'projects', 'combining', 'programming', 'ironhack39s', 'meant', 'help', 'secure', 'spot', 'industryhowever', 'important', 'skill', 'away', 'ability', 'technology', 'fastmoving', 'everchanging', 'context', 'httpschemaorg', 'type', 'fulltime', 'description', 'provider', 'localbusiness', 'ironhack', 'sameas', 'httpwwwironhackcomenutmsourcecoursereport', 'utmmediumschoolpage', '8', 'week', 'immersive', 'catered', 'beginners', 'previous', 'design', 'technical', 'experience', 'taught', 'fundamentals', 'user', 'centered', 'validate', 'ideas', 'research', 'rapid', 'prototyping', 'heuristic', 'evaluation', 'end', 'capstone', 'project', 'new', 'product', 'idea', 'validation', 'launch', 'ready', 'start', 'career', 'ux', 'designer', 'freelance', 'turbo', 'charge', 'current', 'professional', 'trajectory', 'uxui', 'parttime', 'meets', 'tuesdays', 'thursdays', 'saturdays', 'additional', 'online', 'coursework', 'period', '6', 'months', 'build', 'stack', 'javascript', 'web', 'applications', 'big', 'emphasis', 'battletested', 'patterns', 'best', 'practices', 'evaluate', 'problem', 'select', 'optimal', 'solution', 'languageframework', 'suited', 's', 'scopein', 'addition', 'train', 'think', 'like', 'programmer', 'deconstruct', 'complex', 'problems', 'break', 'smaller', 'moduleshowever', 'good', 'general', 'understanding', 'various', 'languages', 'great', 'understands', 'fundamental', 'structure', 'possesses', 'language', 'required', 'development', 'heard', 'knew', 'needed', 'complete', 'education', 'completely', 'right', 'background', 'desire', 'improve', 'developer', 'little', 'grew', 'able', 'overcome', 'challenges', 'thought', 'possible', 'enormous', 'support', 'teacher', 'assistants', 'colleges', 'friends', 'difficulti', 'coding', 'worked', 'biomedical', 'just', 'looking', 'approach', 'totally', 'style', 'life', 'learning', 'curve', 'verticle', 'upwards', 'started', '0', 'im', 'amazed', 'knowwhen', 'visited', 'tuenti', 'spanish', 'company', 'understood', 'talking', 'working', 'doesnt', 'teach', 'code', 'teaches', 'developer100', 'recommendablei', 'impressed', 'professor', 'alan', 'extremely', 'knowledgeable', 'person', 'natural', 'aptitude', 'teaching', 'patient', 'courteous', 'welcoming', 'questions', 'feedback', 'taking', 'time', 'ask', 'running', 'really', 'bit', 'class', 'curriculum', 'challenge', 'computer', 'science', 'prepare', 'scientists', 'types', 'likely', 'interview', 'explain', 'different', 'ways', 'terms', 'complexity', 'memory', 'management', 'expected', 'lessons', 'particularly', 'rewarding', 'knack', 'breaking', 'abstract', 'concepts', 'digestible', 'bits', 'getting', 'comfortable', 'try', 'collectively', 'attempt', 'protip', 'volunteer', 'solve', 'presents', 'noticed', 'brave', 'retained', 'information', 'better', 'walked', 'solid', 'gives', 'marker', 'effort', 'home', 'whiteboard', 'house', 'write', 'objectives', 'goals', 'examples', 'force', 'brain', 'reconcile', 'daily', 'basis', 'certainly', 'job', 'interviews', 'theyre', 'frustrating', 'preparedafter', 'graduation', 'youll', 'counseled', 'brito', 'counselor', 'cool', 'downtoearth', 'wisdom', 'share', 'interviewing', 'process', 'construct', 'resume', 'specifically', 'tells', 'reach', 'accepting', 'offers', 'insight', 'willingness', 'supportive', 'helpful', 'make', 'sure', 'land', 'starting', 'thankful', 'humbled', 'opportunity', 'study', 'awesome', 'classmates', 'teachers', 'absolute', 'pleasure', 'deal', 'blown', 'dev', 'got', 'chance', 'work', 'hackathon', 'impressive', 'legitimately', 'wish', 'absolutely', 'blew', 'mind', 'systematic', 'methodology', 'creativity', 'organized', 'processes', 'amazing', 'loved', 'wrap', 'wholeheartedly', 'recommended', 'ironhacks', '110', 'actively', 'participate', 'engaged', 'positive', 'attitude', 'lifechanging', 'event', 'concrete', 'situation', 'following', 'speed', 'need', 'fast', 'muchits', 'people', 'thinks', 'pushed', 'level', 'highthe', 'instructors', 'friendly', 'open', 'discuss', 'asked', 'imagine', 'staff', 'did', 'receive', 'motivated', 'fact', 'interviewed', 'companies', 'google', 'ibm', 'decided', 'itthis', 'rails', 'environment', 'difficult', 'places', 'professionals', 'incredibly', 'talented', 'group', 'studentsironhack', 'gave', 'didnt', 'wanted', 'hire', 'improving', 'place', 'findvar', 'newwindowfunction', 'openverifyproviderurl', 'var', 'screenx', 'typeof', 'windowscreenx', 'undefined', 'windowscreenleft', 'screeny', 'windowscreeny', 'windowscreentop', 'outerwidth', 'windowouterwidth', 'documentbodyclientwidth', 'outerheight', 'windowouterheight', 'documentbodyclientheight', '22', 'left', 'parseintscreenx', '800', '2', '10', 'parseintscreeny', '25', 'features', 'width800height800left', 'review', 'verifyreviewdatareviewtostring', 'params', 'reviewid', 'url', 'providerurl', 'bodycsscursor', 'progress', 'newwindow', 'windowopenurl', 'login', 'windowfocus', 'newwindowfocus', 'return', 'falsefunction', 'emailverifyproviderurl', 'verifyreviewdataurltostring', 'post', 'sendconfirmation', 'successfunctiondata', 'preconfirmationhide', 'confirmedviaemailshow', 'bottombuffershow', 'closeinstructionsmodal', 'function', 'instructionsoverlayfadeout250', 'duplicateinstructionsoverlayfadeout250', 'falseinstructionsconfirm', 'instructionscloseonclick', 'closeinstructionsmodalvar', 'closethismodal', 'confirmscholarshipoverlayfadeout500', 'bodycssoverflow', 'scrollfunction', 'viewscholarships', 'windowlocationhref', 'researchcenterscholarshipsvar', 'scroll', 'goal', 'discovering', 'informing', 'conclusions', 'supporting', 'decisionmaking', 'analysis', 'multiple', 'facets', 'approaches', 'encompassing', 'diverse', 'techniques', 'variety', 'names', 'used', 'social', 'domains', 'varieties', 'synonym', 'modeling', 'tables', 'charts', 'communicate', 'key', 'messages', 'contained', 'lookup', 'specific', 'numbers', 'bar', 'line', 'quantitative', 'datastephen', 'described', 'users', 'understand', 'set', 'associated', 'graphs', 'message', 'customers', 'specifying', 'requirements', 'analysts', 'performing', 'consider', 'processauthor', 'jonathan', 'koomey', 'series', 'include', 'variables', 'individual', 'values', 'cluster', 'mean', 'add', 'layer', 'relationship', 'referred', 'mutually', 'exclusive', 'exhaustive', 'mece', 'example', 'profit', 'definition', 'broken', 'total', 'revenue', 'cost', 'turn', 'analyzed', 'components', 'divisions', 'b', 'c', 'relate', 'supports', 'rejecting', 'hypothesis', 'trying', 'determine', 'extent', 'independent', 'variable', 'x', 'affects', 'dependent', 'y', 'changes', 'unemployment', 'rate', 'affect', 'inflation', 'model', 'fit', 'equation', 'nca', 'allows', 'certain', 'necessary', 'regression', 'uses', 'additive', 'logic', 'xvariable', 'produce', 'outcome', 'xs', 'compensate', 'sufficient', 'condition', 'necessity', 'xvariables', 'allow', 'exist', 'single', 'present', 'compensation', 'possibleexamples1given', 'cases', 'attributes', 'caseswhat', 'z', '2given', 'conditions', 'attribute', 'satisfying', 'conditionswhich', 'satisfy', 'c3given', 'compute', 'aggregate', 'numeric', 'representation', 'value', 'aggregation', 'f', 'given', 'cases4find', 'possessing', 'extreme', 'range', 'setwhat', 'topbottom', 'n', 'respect', 'a5given', 'rank', 'according', 'ordinal', 'metricwhat', 'sorted', 'order', 'a6given', 'span', 'cases7given', 'characterize', 'distribution', 'cases8identify', 'anomalies', 'expectation', 'statistical', 'outlierswhich', 'unexpectedexceptional', 'values9given', 'clusters', 'similar', 'valueswhich', '10given', 'relationships', 'attributeswhat', 'correlation', 'cases11given', 'contextual', 'relevancy', 'userswhich', 'relevant', 'contextbarriers', 'effective', 'audience', 'distinguishing', 'opinion', 'cognitive', 'biases', 'innumeracy', 'sound', 'agree', 'cbo', 'reported', 'examine', 'report', 'makes', 'persons', 'disagree', 'tendency', 'search', 'interpret', 'way', 'confirms', 'ones', 'preconceptions', 'individuals', 'discredit', 'does', 'views', 'commonsizing', 'employed', 'adjusting', 'comparing', 'vs', 'nominal', 'considering', 'population', 'increases', 'demographics', 'apply', 'address', 'section', 'recast', 'financial', 'statements', 'assumptions', 'arrive', 'estimate', 'future', 'cash', 'flow', 'discount', 'based', 'valuation', 'stock', 'similarly', 'analyzes', 'effects', 'policy', 'options', 'governments', 'outlays', 'deficits', 'creating', 'alternative', 'scenarios', 'measures', 'steps', 'carried', 'realise', 'smart', 'buildings', 'building', 'control', 'operations', 'including', 'heating', 'ventilation', 'air', 'conditioning', 'lighting', 'security', 'realised', 'automatically', 'miming', 'needs', 'optimising', 'resources', 'energy', 'timethis', 'contains', 'explanations', 'assist', 'practitioners', 'typical', 'scope', 'wikipedia', 'articlethe', 'quality', 'checked', 'early', 'assessed', 'frequency', 'counts', 'descriptive', 'statistics', 'standard', 'deviation', 'median', 'normality', 'skewness', 'kurtosis', 'histograms', 'compared', 'schemes', 'external', 'possibly', 'corrected', 'comparable', 'initial', 'phase', 'focus', 'question', 'check', 'measurement', 'instruments', 'corresponds', 'literaturethere', 'assess', 'note', 'listedpossible', 'transformations', 'areif', 'randomization', 'procedure', 'success', 'nonrandom', 'sampling', 'instance', 'checking', 'subgroups', 'represented', 'sampleother', 'distortions', 'arethe', 'characteristics', 'sample', 'atalso', 'original', 'plan', 'main', 'analyses', 'specified', 'rewritten', 'decisions', 'madenominal', 'variablesassociationscontinuous', 'variablesdistributionin', 'exploratory', 'confirmatory', 'adopted', 'usually', 'collected', 'clear', 'stated', 'analysing', 'searched', 'models', 'hypotheses', 'tested', 'hard', 'look', 'stability', 'results', 'reliable', 'reproducible', 'thismany', 'methods', 'brief', 'list', 'popular', 'isdifferent', 'organizations', 'hold', 'contests', 'encourage', 'researchers', 'utilize', 'particular', 'wellknown', 'international', 'follows', 'newpp', 'limit', 'reportparsed', 'mw1258cached', '20181023205919cache', 'expiry', '1900800dynamic', 'content', 'falsecpu', 'usage', '0596', 'secondsreal', '0744', 'secondspreprocessor', 'node', 'count', '31771000000preprocessor', 'generated', '01500000post', 'expand', 'size', '729952097152', 'bytestemplate', 'argument', '28332097152', 'byteshighest', 'expansion', 'depth', '1240expensive', 'parser', '5500unstrip', 'recursion', '120unstrip', '621355000000', 'bytesnumber', 'wikibase', 'entities', 'loaded', '3400lua', '023010000', 'secondslua', '576', 'mb50', 'mbtransclusion', 'mscallstemplate10000', '523114', '1', '3198', '167305', 'templatereflist', '1744', '91248', '5', 'templatecitebook', '971', '50806', 'templateisbn', '763', '39937', 'templateaccordingtowhom', '734', '38394', '3', 'templatecitejournal', '698', '36524', 'templateauthoritycontrol', '673', '35217', 'templatesidebarwithcollapsiblelists', '658', '34408', 'templatefixspan', '582', '30459', 'templatedatavisualization', 'saved', 'cache', 'enwikipcacheidhash27209540canonical', 'timestamp', '20181023205918', 'revision', 'id', '862584710', 'retrieved', 'site'], 'term_freq': [[2, 1, 1, 40, 6, 45, 2, 17, 2, 2, 2, 2, 2, 7, 2, 2, 2, 2, 30, 2, 2, 7, 8, 2, 2, 2, 2, 3, 2, 2, 6, 2, 2, 2, 13, 2, 2, 2, 10, 2, 2, 3, 2, 2, 2, 7, 6, 8, 14, 7, 6, 6, 5, 5, 10, 3, 5, 5, 5, 9, 5, 5, 5, 2, 2, 2, 2, 2, 2, 14, 6, 7, 4, 8, 8, 4, 4, 4, 6, 4, 4, 4, 4, 12, 4, 8, 14, 4, 4, 4, 4, 5, 5, 6, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 9, 4, 6, 4, 4, 4, 11, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4, 4, 8, 8, 13, 4, 5, 8, 4, 4, 4, 6, 4, 5, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 3, 2, 2, 1, 1, 1, 2, 1, 1, 1, 5, 1, 1, 2, 2, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 3, 2, 2, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 5, 2, 1, 2, 1, 6, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 3, 1, 3, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 4, 2, 4, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 5, 2, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 57, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 9, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 4, 3, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 17, 2, 1, 1, 1, 1, 3, 2, 1, 6, 1, 1, 1, 1, 1, 2, 4, 3, 4, 5, 2, 1, 2, 1, 1, 2, 5, 1, 2, 3, 1, 19, 1, 1, 1, 1, 1, 1, 4, 2, 1, 1, 1, 1, 1, 2, 4, 1, 8, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 2, 4, 4, 2, 4, 8, 1, 1, 8, 1, 2, 5, 1, 3, 1, 1, 1, 2, 1, 2, 5, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 21, 5, 2, 2, 1, 2, 10, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 4, 1, 1, 1, 2, 3, 1, 2, 2, 1, 1, 2, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 2, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "bow = get_bow_from_docs([\n",
    "        'www.coursereport.com_ironhack.html',\n",
    "        'en.wikipedia.org_Data_analysis.html',\n",
    "        'www.lipsum.com.html'\n",
    "    ],\n",
    "    stop_words.ENGLISH_STOP_WORDS\n",
    ")\n",
    "\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any problem in the output? How do you improve the output?\n",
    "\n",
    "A good way to improve your codes is to look into the HTML data sources and try to understand where the messy output came from. A good data analyst always learns about the data in depth in order to perform the job well.\n",
    "\n",
    "Spend 20-30 minutes to improve your functions or until you feel you are good at string operations. This lab is just a practice so you don't need to stress yourself out. If you feel you've practiced enough you can stop and move on the next challenge question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problems in the output\n",
    "In the output I see that some problems:\n",
    "- some of the words seem \"illegible\"\n",
    "- I can see that the java scripts haven't been take care\n",
    "- If the anchor text of a link is a URL we can't read it or understand it\n",
    "- We can see a lot of words that aren't usefull\n",
    "\n",
    "I think I could improve the Output by making more cleaning functions for the text we couldn't remove:\n",
    "- Remove the scripts\n",
    "- Remove all the header\n",
    "- Remove the comments\n",
    "- Remove URLs\n",
    "- looking at the code and maybe take out other structural parts of the html \n",
    "\n",
    "Also we can make a **clean_html** function to call all the intermediate cleaning functions \n",
    "And a **open_and_clean_function** to call open the files and clean the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take out the entire <head></head> section\n",
    "\n",
    "def remove_head(html):\n",
    "    pattern=\"<head>(.|\\n)*?</head>\"\n",
    "    clean_html = re.sub(pattern,'',html)\n",
    "    return clean_html\n",
    "\n",
    "# Function to take out scripts\n",
    "\n",
    "def remove_script(html):\n",
    "    pattern=\"<script>(.|\\n)*?</script>\"\n",
    "    clean_html = re.sub(pattern,'',html)\n",
    "    return clean_html\n",
    "\n",
    "# Function to take out noscripts\n",
    "\n",
    "def remove_noscript(html):\n",
    "    pattern=\"<noscript>(.|\\n)*?</noscript>\"\n",
    "    clean_html = re.sub(pattern,'',html)\n",
    "    return clean_html\n",
    "\n",
    "# Function to take out comments\n",
    "\n",
    "def remove_comments(html):\n",
    "    pattern=\"<!--(.|\\n)*?-->\"\n",
    "    clean_html = re.sub(pattern,'',html)\n",
    "    return clean_html\n",
    "\n",
    "# Function to take out URLs\n",
    "\n",
    "def remove_url(html):\n",
    "    pattern=\"https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+\"\n",
    "    clean_html = re.sub(pattern,'',html)\n",
    "    return clean_html\n",
    "\n",
    "def clean_html(txt):\n",
    "    clean_html = 0\n",
    "    clean_html = to_lower_case(txt)       \n",
    "    clean_html = remove_head(clean_html) \n",
    "    clean_html = remove_comments(clean_html) \n",
    "    clean_html = remove_script(clean_html)        \n",
    "    clean_html = remove_noscript(clean_html)        \n",
    "    clean_html = remove_url(clean_html)        \n",
    "    clean_html = strip_html_tags(clean_html)\n",
    "    clean_html = remove_unicode(clean_html)\n",
    "    clean_html = remove_punctuation(clean_html)    \n",
    "    return clean_html\n",
    "\n",
    "def open_and_clean_html(file):\n",
    "    file_txt = open(file, \"r\")  \n",
    "    txt = file_txt.read()\n",
    "    txt = clean_html(txt)       \n",
    "    pattern = \"\\w+\"\n",
    "    txt = (\" \".join(re.findall(pattern, txt)))\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improved get_bow_from_docs\n",
    "\n",
    "def get_bow_from_docs(docs, stop_words=[]):\n",
    "    # In the function, first define the variables you will use such as `corpus`, `bag_of_words`, and `term_freq`.\n",
    "    corpus = []\n",
    "    bag_of_words = []\n",
    "    term_freq = []\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `docs` and read the content of each doc into a string in `corpus`.\n",
    "    Remember to convert the doc content to lowercases and remove punctuation.\n",
    "    \"\"\"\n",
    "    for file in docs:\n",
    "        file_txt = open(file, \"r\")  \n",
    "        txt = file_txt.read()\n",
    "        txt = clean_html(txt)       \n",
    "        pattern = \"\\w+\"\n",
    "        txt = (\" \".join(re.findall(pattern, txt)))\n",
    "        corpus.append(txt)\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `corpus`. Append the terms in each doc into the `bag_of_words` array. The terms in `bag_of_words` \n",
    "    should be unique which means before adding each term you need to check if it's already added to the array.\n",
    "    In addition, check if each term is in the `stop_words` array. Only append the term to `bag_of_words`\n",
    "    if it is not a stop word.\n",
    "    \"\"\"\n",
    "    for string in corpus:\n",
    "        terms = string.split()\n",
    "        for term in terms:\n",
    "            if term not in bag_of_words and term not in stop_words:\n",
    "                bag_of_words.append(term)\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `corpus` again. For each doc string, count the number of occurrences of each term in `bag_of_words`. \n",
    "    Create an array for each doc's term frequency and append it to `term_freq`.\n",
    "    \"\"\"\n",
    "    for string in corpus:\n",
    "        string_terms = string.split()\n",
    "        string_term_count = []\n",
    "        for term in bag_of_words:\n",
    "            count = 0\n",
    "            for i in range(0, len(string_terms)):\n",
    "                if term == string_terms[i]:\n",
    "                    count += 1\n",
    "            string_term_count.append(count)   \n",
    "        term_freq.append(string_term_count)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"bag_of_words\": bag_of_words,\n",
    "        \"term_freq\": term_freq\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bag_of_words': ['course', 'enables', 'students', 'fledged', 'data', 'analyst', '9', 'weeks', 'develop', 'practical', 'skills', 'useful', 'industry', 'rampup', 'prework', 'learn', 'intermediate', 'topics', 'analytics', 'using', 'pandas', 'engineering', 'create', 'application', 'real', 'datasets', 'you39ll', 'use', 'python', 'business', 'intelligencethrough', 'bootcamp', 'doing', 'projects', 'combining', 'programming', 'ironhack39s', 'meant', 'help', 'secure', 'spot', 'industryhowever', 'important', 'skill', 'away', 'ability', 'technology', 'fastmoving', 'everchanging', 'context', 'type', 'fulltime', 'description', 'provider', 'localbusiness', 'ironhack', 'sameas', 'enutmsourcecoursereport', 'utmmediumschoolpage', '8', 'week', 'immersive', 'catered', 'beginners', 'previous', 'design', 'technical', 'experience', 'taught', 'fundamentals', 'user', 'centered', 'validate', 'ideas', 'research', 'rapid', 'prototyping', 'heuristic', 'evaluation', 'end', 'capstone', 'project', 'new', 'product', 'idea', 'validation', 'launch', 'ready', 'start', 'career', 'ux', 'designer', 'freelance', 'turbo', 'charge', 'current', 'professional', 'trajectory', 'uxui', 'parttime', 'meets', 'tuesdays', 'thursdays', 'saturdays', 'additional', 'online', 'coursework', 'period', '6', 'months', 'build', 'stack', 'javascript', 'web', 'applications', 'big', 'emphasis', 'battletested', 'patterns', 'best', 'practices', 'evaluate', 'problem', 'select', 'optimal', 'solution', 'languageframework', 'suited', 's', 'scopein', 'addition', 'train', 'think', 'like', 'programmer', 'deconstruct', 'complex', 'problems', 'break', 'smaller', 'moduleshowever', 'good', 'general', 'understanding', 'various', 'languages', 'great', 'understands', 'fundamental', 'structure', 'possesses', 'language', 'required', 'development', 'heard', 'knew', 'needed', 'complete', 'education', 'completely', 'right', 'background', 'desire', 'improve', 'developer', 'little', 'grew', 'able', 'overcome', 'challenges', 'thought', 'possible', 'enormous', 'support', 'teacher', 'assistants', 'colleges', 'friends', 'difficulti', 'coding', 'worked', 'biomedical', 'just', 'looking', 'approach', 'totally', 'style', 'life', 'learning', 'curve', 'verticle', 'upwards', 'started', '0', 'im', 'amazed', 'knowwhen', 'visited', 'tuenti', 'spanish', 'company', 'understood', 'talking', 'working', 'doesnt', 'teach', 'code', 'teaches', 'developer100', 'recommendablei', 'impressed', 'professor', 'alan', 'extremely', 'knowledgeable', 'person', 'natural', 'aptitude', 'teaching', 'patient', 'courteous', 'welcoming', 'questions', 'feedback', 'taking', 'time', 'ask', 'running', 'really', 'bit', 'class', 'curriculum', 'challenge', 'computer', 'science', 'prepare', 'scientists', 'types', 'likely', 'interview', 'explain', 'different', 'ways', 'terms', 'complexity', 'memory', 'management', 'expected', 'lessons', 'particularly', 'rewarding', 'knack', 'breaking', 'abstract', 'concepts', 'digestible', 'bits', 'getting', 'comfortable', 'try', 'collectively', 'attempt', 'protip', 'volunteer', 'solve', 'presents', 'noticed', 'brave', 'retained', 'information', 'better', 'walked', 'solid', 'gives', 'marker', 'effort', 'home', 'whiteboard', 'house', 'write', 'objectives', 'goals', 'examples', 'force', 'brain', 'reconcile', 'daily', 'basis', 'certainly', 'job', 'interviews', 'theyre', 'frustrating', 'preparedafter', 'graduation', 'youll', 'counseled', 'brito', 'counselor', 'cool', 'downtoearth', 'wisdom', 'share', 'interviewing', 'process', 'construct', 'resume', 'specifically', 'tells', 'reach', 'accepting', 'offers', 'insight', 'willingness', 'supportive', 'helpful', 'make', 'sure', 'land', 'starting', 'thankful', 'humbled', 'opportunity', 'study', 'awesome', 'classmates', 'teachers', 'absolute', 'pleasure', 'deal', 'blown', 'dev', 'got', 'chance', 'work', 'hackathon', 'impressive', 'legitimately', 'wish', 'absolutely', 'blew', 'mind', 'systematic', 'methodology', 'creativity', 'organized', 'processes', 'amazing', 'loved', 'wrap', 'wholeheartedly', 'recommended', 'ironhacks', '110', 'actively', 'participate', 'engaged', 'positive', 'attitude', 'lifechanging', 'event', 'concrete', 'situation', 'following', 'speed', 'need', 'fast', 'muchits', 'people', 'thinks', 'pushed', 'level', 'highthe', 'instructors', 'friendly', 'open', 'discuss', 'asked', 'imagine', 'staff', 'did', 'receive', 'motivated', 'fact', 'interviewed', 'companies', 'google', 'ibm', 'decided', 'itthis', 'rails', 'environment', 'difficult', 'places', 'professionals', 'incredibly', 'talented', 'group', 'studentsironhack', 'gave', 'didnt', 'wanted', 'hire', 'improving', 'place', 'goal', 'discovering', 'informing', 'conclusions', 'supporting', 'decisionmaking', 'analysis', 'multiple', 'facets', 'approaches', 'encompassing', 'diverse', 'techniques', 'variety', 'names', 'used', 'social', 'domains', 'varieties', 'synonym', 'modeling', 'tables', 'charts', 'communicate', 'key', 'messages', 'contained', 'lookup', 'specific', 'numbers', 'bar', 'line', 'quantitative', 'datastephen', 'described', 'users', 'understand', 'set', 'associated', 'graphs', 'message', 'customers', 'specifying', 'requirements', 'analysts', 'performing', 'consider', 'processauthor', 'jonathan', 'koomey', 'series', 'include', 'variables', 'individual', 'values', 'cluster', 'mean', 'add', 'layer', 'relationship', 'referred', 'mutually', 'exclusive', 'exhaustive', 'mece', 'example', 'profit', 'definition', 'broken', 'total', 'revenue', 'cost', 'turn', 'analyzed', 'components', 'divisions', 'b', 'c', 'relate', 'supports', 'rejecting', 'hypothesis', 'trying', 'determine', 'extent', 'independent', 'variable', 'x', 'affects', 'dependent', 'y', 'changes', 'unemployment', 'rate', 'affect', 'inflation', 'model', 'fit', 'equation', 'function', 'nca', 'allows', 'certain', 'necessary', 'regression', 'uses', 'additive', 'logic', 'xvariable', 'produce', 'outcome', 'xs', 'compensate', 'sufficient', 'condition', 'necessity', 'xvariables', 'allow', 'exist', 'single', 'present', 'compensation', 'possibleexamples1given', 'cases', 'attributes', 'caseswhat', 'z', '2given', 'conditions', 'attribute', 'satisfying', 'conditionswhich', 'satisfy', 'c3given', 'compute', 'aggregate', 'numeric', 'representation', 'value', 'aggregation', 'f', 'given', 'cases4find', 'possessing', 'extreme', 'range', 'setwhat', 'topbottom', 'n', 'respect', 'a5given', 'rank', 'according', 'ordinal', 'metricwhat', 'sorted', 'order', 'a6given', 'span', 'cases7given', 'characterize', 'distribution', 'cases8identify', 'anomalies', 'expectation', 'statistical', 'outlierswhich', 'unexpectedexceptional', 'values9given', 'clusters', 'similar', 'valueswhich', '10given', 'relationships', 'attributeswhat', 'correlation', 'cases11given', 'contextual', 'relevancy', 'userswhich', 'relevant', 'contextbarriers', 'effective', 'audience', 'distinguishing', 'opinion', 'cognitive', 'biases', 'innumeracy', 'sound', 'agree', 'cbo', 'reported', 'examine', 'report', 'makes', 'persons', 'disagree', 'tendency', 'search', 'interpret', 'way', 'confirms', 'ones', 'preconceptions', 'individuals', 'discredit', 'does', 'views', 'commonsizing', 'employed', 'adjusting', 'comparing', 'vs', 'nominal', 'considering', 'population', 'increases', 'demographics', 'apply', 'address', 'section', 'recast', 'financial', 'statements', 'assumptions', 'arrive', 'estimate', 'future', 'cash', 'flow', 'discount', 'based', 'valuation', 'stock', 'similarly', 'analyzes', 'effects', 'policy', 'options', 'governments', 'outlays', 'deficits', 'creating', 'alternative', 'scenarios', 'measures', 'steps', 'carried', 'realise', 'smart', 'buildings', 'building', 'control', 'operations', 'including', 'heating', 'ventilation', 'air', 'conditioning', 'lighting', 'security', 'realised', 'automatically', 'miming', 'needs', 'optimising', 'resources', 'energy', 'timethis', 'contains', 'explanations', 'assist', 'practitioners', 'typical', 'scope', 'wikipedia', 'articlethe', 'quality', 'checked', 'early', 'assessed', 'frequency', 'counts', 'descriptive', 'statistics', 'standard', 'deviation', 'median', 'normality', 'skewness', 'kurtosis', 'histograms', 'compared', 'schemes', 'external', 'possibly', 'corrected', 'comparable', 'initial', 'phase', 'focus', 'question', 'check', 'measurement', 'instruments', 'corresponds', 'literaturethere', 'assess', 'note', 'listedpossible', 'transformations', 'areif', 'randomization', 'procedure', 'success', 'nonrandom', 'sampling', 'instance', 'checking', 'subgroups', 'represented', 'sampleother', 'distortions', 'arethe', 'characteristics', 'sample', 'atalso', 'original', 'plan', 'main', 'analyses', 'specified', 'rewritten', 'decisions', 'madenominal', 'variablesassociationscontinuous', 'variablesdistributionin', 'exploratory', 'confirmatory', 'adopted', 'usually', 'collected', 'clear', 'stated', 'analysing', 'searched', 'models', 'hypotheses', 'tested', 'hard', 'look', 'stability', 'results', 'reliable', 'reproducible', 'thismany', 'methods', 'brief', 'list', 'popular', 'isdifferent', 'organizations', 'hold', 'contests', 'encourage', 'researchers', 'utilize', 'particular', 'wellknown', 'international', 'follows', 'retrieved', 'site'], 'term_freq': [[40, 6, 45, 2, 17, 2, 2, 2, 2, 2, 7, 2, 2, 2, 2, 30, 2, 2, 7, 8, 2, 2, 2, 2, 3, 2, 2, 6, 2, 2, 2, 13, 2, 2, 2, 10, 2, 2, 3, 2, 2, 2, 7, 6, 8, 14, 7, 6, 6, 5, 10, 3, 5, 5, 5, 9, 5, 5, 5, 2, 2, 2, 2, 2, 2, 14, 6, 7, 4, 8, 8, 4, 4, 4, 6, 4, 4, 4, 4, 12, 4, 8, 14, 4, 4, 4, 4, 5, 5, 6, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 9, 4, 6, 4, 4, 4, 11, 4, 4, 5, 4, 4, 5, 4, 4, 5, 4, 4, 4, 8, 8, 13, 4, 5, 8, 4, 4, 4, 6, 4, 5, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 3, 2, 2, 1, 1, 1, 2, 1, 1, 1, 5, 1, 1, 2, 2, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 3, 2, 2, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 5, 2, 1, 2, 1, 6, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 3, 1, 3, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 57, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 9, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 4, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 17, 2, 1, 1, 1, 1, 3, 2, 1, 6, 1, 1, 1, 1, 1, 2, 4, 3, 3, 5, 2, 1, 2, 1, 1, 2, 5, 1, 2, 3, 1, 19, 1, 1, 1, 1, 1, 1, 4, 2, 1, 1, 1, 1, 1, 1, 4, 1, 8, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 4, 5, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 2, 4, 4, 2, 4, 8, 1, 1, 8, 1, 2, 5, 1, 3, 1, 1, 1, 2, 2, 1, 2, 5, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 21, 5, 2, 2, 1, 2, 10, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 4, 1, 1, 1, 2, 3, 1, 2, 2, 1, 1, 2, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "bow = get_bow_from_docs([\n",
    "        'www.coursereport.com_ironhack.html',\n",
    "        'en.wikipedia.org_Data_analysis.html',\n",
    "        'www.lipsum.com.html'\n",
    "    ],\n",
    "    stop_words.ENGLISH_STOP_WORDS\n",
    ")\n",
    "\n",
    "print(bow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
